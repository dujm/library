{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849a5f67-e079-4b48-85dd-1f18e26e8239",
   "metadata": {},
   "source": [
    "# Coni\n",
    "### Who is Coni?   \n",
    " * Coni is **a librarian-like LLM agent**, who works with digital collections (images, text, etc.)\n",
    " * This notebooks shows how Coni can do **visual Q&A**.\n",
    "\n",
    "### How was Coni created? \n",
    " * Agent creation framework: `Langchain`\n",
    " * LLM model:Cohere's  `command-r` LLM model\n",
    " * A visual Q&A tool: using Salesforce's visual Q&A model (`blip-vqa-base`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7617fb3-8f4b-450c-b061-e8c03d763e29",
   "metadata": {},
   "source": [
    "# 1. Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccabc01-9e41-4e0a-a26f-331e2a0fceea",
   "metadata": {},
   "source": [
    "### To use Cohere's `command-r` LLM model\n",
    " * get an API key from https://cohere.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6765b7-255f-4f81-9c39-6785941a5256",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c304bd8-f6d2-4313-8b92-813dcea0f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the packages if they are not installed yet \n",
    "#%pip install langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab3e889-d396-497e-b8d2-a03feb9cecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# color text when printing\n",
    "from termcolor import colored\n",
    "\n",
    "# to send http requests\n",
    "import requests\n",
    "\n",
    "# python imaging library\n",
    "from PIL import Image\n",
    "\n",
    "# for using model through langchain_cohere\n",
    "from langchain_cohere.chat_models import ChatCohere\n",
    "\n",
    "# for agents\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_cohere.react_multi_hop.agent import create_cohere_react_agent\n",
    "\n",
    "# for prompting\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# for using BLIP model\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# load the .env file (for saving API keys, see details in `.env_example file`)\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bbaa2-4456-4121-8cea-ce24fd7c8d0e",
   "metadata": {},
   "source": [
    "## 2. Create 'Coni'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50817d79-a5b5-48d6-abf9-ee006ecd75fc",
   "metadata": {},
   "source": [
    "### 1) Choose an LLM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab15204-d07e-4472-a8e9-509460835541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model id\n",
    "llm_model_id = \"command-r\"\n",
    "\n",
    "# llm model\n",
    "llm = ChatCohere(model=llm_model_id,temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acded24e-1cce-4425-8b16-8cd8bb3961d0",
   "metadata": {},
   "source": [
    "### 2) Prepare tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70f7585-e48a-4596-98ad-a5548b3de39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesforce's visual q&a model\n",
    "vqa_model = \"Salesforce/blip-vqa-base\"\n",
    "\n",
    "# a function for do image qa\n",
    "def VisualQA(image_url,question, vqa_model = vqa_model) : \n",
    "\n",
    "    processor = BlipProcessor.from_pretrained(vqa_model)\n",
    "    model = BlipForQuestionAnswering.from_pretrained(vqa_model)\n",
    "\n",
    "    # open image\n",
    "    raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
    "    inputs = processor(raw_image, question, return_tensors=\"pt\")\n",
    "    \n",
    "    outputs= model.generate(**inputs, max_length= 1000)\n",
    "    return processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# convert to a langchain tool\n",
    "class VisualQATool(BaseTool):\n",
    "    name = \"Visual QA Tool\"\n",
    "    description = 'use this tool to understand an image and generate content.'\n",
    "\n",
    "    def _run(self, url: str, question: str):\n",
    "        description = VisualQA(url,question)\n",
    "        return description\n",
    "\n",
    "# a list of tools to give to the agent\n",
    "tools = [VisualQATool()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e48515-899c-4237-ad97-e9c58f8cbba1",
   "metadata": {},
   "source": [
    "### 3) Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419f38a0-1923-4878-8c4e-aa7a3a7d4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cohere react agent\n",
    "agent = create_cohere_react_agent(\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        prompt=ChatPromptTemplate.from_template(\"{question}\")\n",
    "    )\n",
    "\n",
    "# calls the agent\n",
    "agent_executor = AgentExecutor(agent=agent, \n",
    "                               tools=tools, \n",
    "                               intermediate_steps=False,\n",
    "                               verbose=False,\n",
    "                               handle_parsing_errors=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0a3e5-0fae-440c-8cdd-38bd6c0f664f",
   "metadata": {},
   "source": [
    "## 3. Ask Coni questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df0c7e-9069-449d-811b-843b18d43a80",
   "metadata": {},
   "source": [
    "### Input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb84669-7d51-4b86-b138-ee763fe13cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image url \n",
    "image_url = 'https://images.newscientist.com/wp-content/uploads/2018/08/23130240/by0ndk.jpg?width=900'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224a437-fd7d-40a5-8f1f-ff079ace8d2b",
   "metadata": {},
   "source": [
    "### Have a look at the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57be9dd-5e0c-494f-bc6e-eab16cb29def",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src='https://images.newscientist.com/wp-content/uploads/2018/08/23130240/by0ndk.jpg?width=900'\n",
    "    width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09451f4a-5750-4ee6-8449-e225b30ff78e",
   "metadata": {},
   "source": [
    "### Question 1: What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc2b700-5bd1-4e83-9da0-80bcbd2687cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mThe image contains clownfish.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question\n",
    "question= f\"What do you find in :\\n{image_url}\"\n",
    "\n",
    "# agent at work \n",
    "content=agent_executor.invoke(\n",
    "                {\"question\":question})\n",
    "\n",
    "# generated description \n",
    "description = content['output']\n",
    "\n",
    "\n",
    "# print in color\n",
    "print(colored(description, 'light_cyan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c00ac7-6d8c-4a8e-a899-6d2970a9713f",
   "metadata": {},
   "source": [
    "### Question 2: How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b159c7-91a7-4375-8726-a62b209d984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mI can see two fish in the image.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question\n",
    "question= f\"How many fish do you see in :\\n{image_url}\"\n",
    "\n",
    "# agent at work \n",
    "content=agent_executor.invoke(\n",
    "                {\"question\":question})\n",
    "\n",
    "# generated description \n",
    "description = content['output']\n",
    "\n",
    "\n",
    "# print in color \n",
    "print(colored(description, 'light_cyan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ba5bd-fc6e-4b95-bf2f-d78ed5b61477",
   "metadata": {},
   "source": [
    "### Question 3: Tell a story?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f0b5d9-5044-4d83-80ef-cd8347ad9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mOnce upon a time, in a kingdom beneath the sea, there lived a young clownfish named Barry. Barry was an adventurous soul and dreamed of exploring the world above the waves. One day, while swimming near the coral reef, Barry spotted something strangeâ€”a bright, mysterious light beaming from the surface. Curiosity piqued, he decided to investigate. Swimming closer, he was amazed to discover a magical portal opening into a vibrant, unknown realm. Excited, Barry swam through the portal and found himself in a colourful new world, full of strange and wonderful creatures.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# question\n",
    "question= f\"Can you please tell an interesting and creative story in 100 words:\\n{image_url}\"\n",
    "\n",
    "# agent at work \n",
    "content=agent_executor.invoke(\n",
    "                {\"question\":question})\n",
    "\n",
    "# generated description \n",
    "description = content['output']\n",
    "\n",
    "# print\n",
    "print(colored(description, 'light_cyan'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "library",
   "language": "python",
   "name": "library"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
